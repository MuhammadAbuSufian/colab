{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOBML354gKeRqf3tY+2StoQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhammadAbuSufian/predicting-image/blob/main/Clip_Predicting_Image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6C4dqR4OdZZT"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from PIL import Image\n",
        "import requests\n",
        "import torch\n",
        "\n",
        "# Load CLIP model and processor\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "\n",
        "# Define the function to create an image grid\n",
        "def image_grid(imgs, cols):\n",
        "    rows = (len(imgs) + cols - 1) // cols\n",
        "    w, h = imgs[0].size\n",
        "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
        "\n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
        "    return grid\n",
        "\n",
        "# Define the URLs of images from the COCO dataset\n",
        "image_urls = [\n",
        "    'http://images.cocodataset.org/val2014/COCO_val2014_000000159977.jpg',\n",
        "    'http://images.cocodataset.org/val2014/COCO_val2014_000000311295.jpg',\n",
        "    'http://images.cocodataset.org/val2014/COCO_val2014_000000457834.jpg',\n",
        "    'http://images.cocodataset.org/val2014/COCO_val2014_000000555472.jpg',\n",
        "    'http://images.cocodataset.org/val2014/COCO_val2014_000000174070.jpg',\n",
        "    'http://images.cocodataset.org/val2014/COCO_val2014_000000460929.jpg'\n",
        "]\n",
        "\n",
        "# Load images from URLs\n",
        "images = []\n",
        "for url in image_urls:\n",
        "    images.append(Image.open(requests.get(url, stream=True).raw))\n",
        "\n",
        "# Display images in a grid\n",
        "grid = image_grid(images, cols=3)\n",
        "display(grid)\n",
        "\n",
        "# Perform image classification\n",
        "classes = ['giraffe', 'zebra', 'elephant']\n",
        "inputs = processor(text=classes, images=images, return_tensors=\"pt\", padding=True, do_convert_rgb=False)\n",
        "\n",
        "outputs = model(**inputs)\n",
        "logits_per_image = outputs.logits_per_image  # This is the image-text similarity score\n",
        "probs = logits_per_image.softmax(dim=1)  # Calculate softmax probabilities\n",
        "\n",
        "# Print the classification results\n",
        "for i, prob in enumerate(probs):\n",
        "    pred_class_idx = torch.argmax(prob)\n",
        "    pred_class = classes[pred_class_idx]\n",
        "    print(f\"Image {i+1}: Predicted class is '{pred_class}' with probability {prob[pred_class_idx]:.2f}\")"
      ]
    }
  ]
}