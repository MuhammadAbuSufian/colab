{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRS6O/QdmhlkwhPuOicZ8r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhammadAbuSufian/predicting-image/blob/main/ImageReward.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install image-reward\n",
        "!pip install torch==1.10.0+cu102 torchvision==0.11.1+cu102 torchaudio==0.10.0+cu102 -f https://download.pytorch.org/whl/cu102/torch_stable.html\n",
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import ImageReward as RM\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    prompt = \"A elephant is waking\"\n",
        "    img_urls = [\n",
        "\t\t'http://images.cocodataset.org/val2014/COCO_val2014_000000555472.jpg',\n",
        "\t\t'http://images.cocodataset.org/val2014/COCO_val2014_000000311295.jpg',\n",
        "    ]\n",
        "    img_list = []\n",
        "\n",
        "    # Download images from URLs\n",
        "    for url in img_urls:\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            # Convert the response content to a PIL image\n",
        "            img = Image.open(BytesIO(response.content))\n",
        "            img_list.append(img)\n",
        "        else:\n",
        "            print(f\"Failed to load image from URL: {url}\")\n",
        "\n",
        "    model = RM.load(\"ImageReward-v1.0\")\n",
        "    with torch.no_grad():\n",
        "        ranking, rewards = model.inference_rank(prompt, img_list)\n",
        "        # Print the result\n",
        "        print(\"\\nPreference predictions:\\n\")\n",
        "        print(f\"ranking = {ranking}\")\n",
        "        print(f\"rewards = {rewards}\")\n",
        "        for index in range(len(img_list)):\n",
        "            score = model.score(prompt, img_list[index])\n",
        "            print(f\"Image {index + 1}: {score:.2f}\")\n"
      ],
      "metadata": {
        "id": "4p91-oLGF8mV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}